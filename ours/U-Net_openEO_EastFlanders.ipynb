{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet-based water detection on scene level using openEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to demonstrate how to do model inference using openEO. This can be done using a user-defined function (https://open-eo.github.io/openeo-python-client/udf.html). \n",
    "\n",
    "Below two U-Nets for water detection can be applied, 1) using Sentinel-2 bands B2, B3, B4 and B8, and 2) using Sentinel-2 bands B2, B3, B4, B8, B11 and B12 as well as Sentinel-1 bands VV and VH.\n",
    "\n",
    "The final section illustrates how to locally debug when developping your UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import shape, box\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import openeo\n",
    "import contextily as cx\n",
    "## For local test\n",
    "from pathlib import Path\n",
    "from openeo.udf import execute_local_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plotting_array(dataarray, vmin=0, vmax=0.25, scale=1e4):\n",
    "    \"\"\" scale xr array to 0-1 using the defined lower and upper limits and scale, for plotting with matplotlib \"\"\"\n",
    "    arr = dataarray.copy()\n",
    "    arr = arr.where(arr <= scale)\n",
    "    arr /= scale\n",
    "    arr = arr.where(arr < vmax, vmax)\n",
    "    arr = arr.where(arr > vmin, vmin)\n",
    "    return (arr - vmin) / (vmax - vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_job_result(job, dir_output, fformat=\"nc\"):\n",
    "    \"\"\" download job result to specifed output directory, file name is taken from job title \"\"\"\n",
    "    if job.status() != \"finished\":\n",
    "        print(\"Job status '{}', aborting.\".format(job.status()))\n",
    "        return None\n",
    "    # Get the results\n",
    "    results = job.get_results()\n",
    "    # Loop over the resulting assets and download        \n",
    "    for i_a, asset in enumerate(results.get_assets()):\n",
    "        asset_suffix = \"-{}\".format(i_a) if i_a > 0 else \"\"\n",
    "        asset_targetname = os.path.join(dir_output, \"{}{}.{}\".format(job.describe_job()[\"title\"], asset_suffix, fformat))\n",
    "        if os.path.exists(asset_targetname):\n",
    "            asset_targetname = asset_targetname.replace(\".{}\".format(fformat), \"-new.{}\".format(fformat))\n",
    "        print(\"{} - Downloading {}\".format(datetime.datetime.now(), asset_targetname))\n",
    "        ts = datetime.datetime.now()\n",
    "        asset.download(asset_targetname)\n",
    "        te = datetime.datetime.now()\n",
    "        print(\"\\tDownload finished after {} sec.\".format(round((te-ts).total_seconds())))\n",
    "    return asset_targetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_s1s2_timerange import scale_sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Connection to 'https://openeo.vito.be/openeo/1.1/' with OidcBearerAuth>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to openeo backend\n",
    "connection = openeo.connect(\"openeo.vito.be\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters: AOI bounds, year, month\n",
    "aoi_name = \"EastFlandersSmall\" #\"EastFlanders\"\n",
    "year = 2022\n",
    "month = 5\n",
    "\n",
    "aoi_bounds = [506800, 5640100, 553400, 5650900] #[466800, 5616100, 603400, 5693900]\n",
    "crs_epsg = 32631\n",
    "\n",
    "spatial_extent = dict(zip([\"west\", \"south\", \"east\", \"north\"], aoi_bounds)) # box(*aoi_bounds).buffer(-30000).bounds)\n",
    "spatial_extent[\"crs\"] = crs_epsg\n",
    "\n",
    "startdate = \"{}-{:02d}-{:02d}\".format(year, month, 1)\n",
    "enddate = \"{}-{:02d}-{:02d}\".format(year, month+1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water detection based on Sentinel-2 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run our UDF on the data cube using the apply_neighborhood() process. We can pass additional arguments for the UDF, like the model path, using the context argument. The size parameter defines the core size of the neighborhoods that are stitched back together, the overlap parameter defines the padding added at each size. So your U-Net should take patches of size+2*overlap as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path (should be stored on MEP)\n",
    "model_dir = \"/work/udf/ours/saved_models/model_20230919084756_bestvalacc.pth\"\n",
    "#path_model = \"/data/users/Public/landuytl/water-detection/PS120_2100-SY-FW0.9_MOP0.005_MOT0.80_S0_C0_2100_S2-4B_D3_F32_W-E_A0_SN_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bands in alignment with model inputs\n",
    "# bands_s2 = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "bands = [\"B04\", \"B03\", \"B02\", \"SCL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datacube\n",
    "input_data = connection.load_collection(\n",
    "    \"TERRASCOPE_S2_TOC_V2\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentationband = input_data.apply_neighborhood(\n",
    "    lambda data: data.run_udf(udf=Path('./unet_udf.py').read_text(), \n",
    "                              runtime='Python', \n",
    "                              context={\"model_path\": \"./saved_models/model_20230919084756_bestvalacc.pth\",\n",
    "    \"model_backbone\": \"Unet\",\n",
    "    \"encoder\": \"timm-regnety_320\",\n",
    "    \"pretrain\": \"imagenet\",\n",
    "    \"in_channel\": 3,\n",
    "    \"classes\": 14}),\n",
    "    size=[\n",
    "        {'dimension': 'x', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 't', 'value': 'P1D'} # this will map the UDF on every scene in the collection (https://en.wikipedia.org/wiki/ISO_8601#Durations)\n",
    "    ],\n",
    "    overlap=[\n",
    "        {'dimension': 'x', 'value': 10, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 10, 'unit': 'px'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "segmentationband = segmentationband.rename_labels(dimension=\"bands\", target=[\"prediction\"] + [\"\"] * (len(bands)-1))\n",
    "segmentationband = segmentationband.filter_bands([\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\work\\udf\\ours\\U-Net_openEO_EastFlanders.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/ours/U-Net_openEO_EastFlanders.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_data\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39m./test_input.nc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNetCDF\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/ours/U-Net_openEO_EastFlanders.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m local_udf \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39m./unet_udf.py\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mread_text()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/work/udf/ours/U-Net_openEO_EastFlanders.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m execute_local_udf(local_udf, \u001b[39m'\u001b[39;49m\u001b[39mtest_input.nc\u001b[39;49m\u001b[39m'\u001b[39;49m, fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnetcdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\openeo\\udf\\run_code.py:199\u001b[0m, in \u001b[0;36mexecute_local_udf\u001b[1;34m(udf, datacube, fmt)\u001b[0m\n\u001b[0;32m    196\u001b[0m     udf \u001b[39m=\u001b[39m udf\u001b[39m.\u001b[39mcode\n\u001b[0;32m    198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(datacube, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPath)):\n\u001b[1;32m--> 199\u001b[0m     d \u001b[39m=\u001b[39m XarrayDataCube\u001b[39m.\u001b[39;49mfrom_file(path\u001b[39m=\u001b[39;49mdatacube, fmt\u001b[39m=\u001b[39;49mfmt)\n\u001b[0;32m    200\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(datacube, XarrayDataCube):\n\u001b[0;32m    201\u001b[0m     d \u001b[39m=\u001b[39m datacube\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\openeo\\udf\\xarraydatacube.py:136\u001b[0m, in \u001b[0;36mXarrayDataCube.from_file\u001b[1;34m(cls, path, fmt, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m fmt \u001b[39m=\u001b[39m fmt \u001b[39mor\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_guess_format(path)\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m fmt\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnetcdf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(array\u001b[39m=\u001b[39mXarrayIO\u001b[39m.\u001b[39mfrom_netcdf_file(path\u001b[39m=\u001b[39mpath, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    137\u001b[0m \u001b[39melif\u001b[39;00m fmt\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(array\u001b[39m=\u001b[39mXarrayIO\u001b[39m.\u001b[39mfrom_json_file(path\u001b[39m=\u001b[39mpath))\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\openeo\\udf\\xarraydatacube.py:320\u001b[0m, in \u001b[0;36mXarrayIO.from_netcdf_file\u001b[1;34m(cls, path, engine)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_netcdf_file\u001b[39m(\u001b[39mcls\u001b[39m, path: Union[\u001b[39mstr\u001b[39m, Path], engine: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m xarray\u001b[39m.\u001b[39mDataArray:\n\u001b[0;32m    319\u001b[0m     \u001b[39m# load the dataset and convert to data array\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     ds \u001b[39m=\u001b[39m xarray\u001b[39m.\u001b[39;49mopen_dataset(path, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    322\u001b[0m     \u001b[39m# Skip non-numerical variables (like \"crs\")\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     band_vars \u001b[39m=\u001b[39m [k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m ds\u001b[39m.\u001b[39mdata_vars\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m} \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(v\u001b[39m.\u001b[39mdims) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\xarray\\backends\\api.py:554\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(backend_kwargs)\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m     engine \u001b[39m=\u001b[39m plugins\u001b[39m.\u001b[39;49mguess_engine(filename_or_obj)\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m from_array_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m     from_array_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\xarray\\backends\\plugins.py:197\u001b[0m, in \u001b[0;36mguess_engine\u001b[1;34m(store_spec)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    191\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfound the following matches with the input file in xarray\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms IO \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackends: \u001b[39m\u001b[39m{\u001b[39;00mcompatible_engines\u001b[39m}\u001b[39;00m\u001b[39m. But their dependencies may not be installed, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m     )\n\u001b[1;32m--> 197\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
     ]
    }
   ],
   "source": [
    "## Local test\n",
    "input_data.download('./test_input.nc', format='NetCDF')\n",
    "local_udf = Path('./unet_udf.py').read_text()\n",
    "execute_local_udf(local_udf, 'test_input.nc', fmt='netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default job resources are 2 executor cores with 2G memory en 3G memory overhead, but these need to be increased for larger AOIs. See https://docs.openeo.cloud/federation/#customizing-batch-job-resources-on-terrascope for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job\n",
    "\n",
    "job_options = { # trial-error based, I'm currently using 2G/6G for the smaller AOIs and 8G/8G for the larger AOIs\n",
    "    \"executor-memory\": \"8G\",\n",
    "    \"executor-memoryOverhead\": \"8G\",\n",
    "    \"executor-cores\": \"4\"\n",
    "}\n",
    "\n",
    "job = segmentationband.create_job(out_format=\"NetCDF\", title=\"BVM_{}_{}_{}\".format(aoi_name, startdate, enddate), job_options=job_options)\n",
    "job.start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up job status\n",
    "connection.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"j-2311143fadc44b3b8c830e2001ebeaab\"\n",
    "j = connection.job(job_id)\n",
    "j.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download result based on job id\n",
    "job_id = \"j-47673edec3104751a2764aa76d257f42\"\n",
    "path_result = download_job_result(connection.job(job_id), os.getcwd(), fformat=\"nc\")\n",
    "print(path_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate result\n",
    "ds = xr.open_dataset(path_result)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of results\n",
    "nc = 4\n",
    "fig, ax = plt.subplots(nc, nc, figsize=(3*nc, 3*nc))\n",
    "for subax in ax.ravel():\n",
    "    t = np.random.choice(ds.t.values)\n",
    "    subax.imshow(ds[\"prediction\"].sel(t=t).values, vmin=0, vmax=1)\n",
    "    subax.set_title(pd.to_datetime(t).strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Water detection based on Sentinel-2 & Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a U-Net requiring both Sentinel-2 and Sentinel-1 input, we need to first temporally align both. This is done within the UDF: for each S-2 scene, the closest S-1 scene that has less nan values than all candidates is selected.\n",
    "\n",
    "We will first extract the dates on which S-1 and S-2 scenes are available, so we can pass this info to the UDF. As we need access to more than just 1 date value to be able to select the closest S-1 scene, we will pass the full datacube to the UDF (size for t dimension undefined), and make the UDF return the full S-2 time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny AOI for testing (temporary)\n",
    "aoi_bounds = [513270, 5644200, 517690, 5647900] #[466800, 5616100, 603400, 5693900]\n",
    "crs_epsg = 32631\n",
    "\n",
    "spatial_extent = dict(zip([\"west\", \"south\", \"east\", \"north\"], aoi_bounds)) # box(*aoi_bounds).buffer(-30000).bounds)\n",
    "spatial_extent[\"crs\"] = crs_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "path_model = \"/data/users/Public/landuytl/water-detection/PS120_2100-SY-FW0.9_MOP0.005_MOT0.80_S0_C1_2100_S2-6B-S1_D3_F32_W-E_A0_fromscratch_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bands in alignment with model inputs\n",
    "bands_s2 = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\", \"SCL\"]\n",
    "bands_s1 = [\"VV\", \"VH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datacube\n",
    "\n",
    "# Get all S2 data\n",
    "input_data_s2 = connection.load_collection(\n",
    "    \"TERRASCOPE_S2_TOC_V2\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands_s2,\n",
    ")\n",
    "\n",
    "# Get all S1 data\n",
    "input_data_s1 = connection.load_collection(\n",
    "    \"SENTINEL1_GRD_SIGMA0\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands_s1,\n",
    ")\n",
    "\n",
    "input_data = input_data_s2.merge_cubes(input_data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S-1 & S-2 dates to pass as input to UDF\n",
    "# input_data_s2.dimension_labels(\"t\").download(\"dates_s2.json\")\n",
    "# input_data_s1.dimension_labels(\"t\").download(\"dates_s1.json\")\n",
    "s1_dates = input_data_s1.dimension_labels(\"t\").execute()\n",
    "s2_dates = input_data_s2.dimension_labels(\"t\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model on openeo server\n",
    "\n",
    "segmentationband = input_data.apply_neighborhood(\n",
    "    lambda data: data.run_udf(udf=Path('unet_s1s2_timerange.py').read_text(), \n",
    "                              runtime='Python', \n",
    "                              context={\"path_model\": path_model,\n",
    "                                      \"s2_dates\": s2_dates,\n",
    "                                      \"s1_dates\": s1_dates}),\n",
    "    size=[\n",
    "        {'dimension': 'x', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 100, 'unit': 'px'}\n",
    "    ],\n",
    "    overlap=[\n",
    "        {'dimension': 'x', 'value': 10, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 10, 'unit': 'px'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "segmentationband = segmentationband.rename_labels(dimension=\"bands\", target=[\"prediction\"] + [\"\"] * (len(bands_s2)+len(bands_s1)-1))\n",
    "segmentationband = segmentationband.filter_bands([\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job\n",
    "\n",
    "job_options = {\n",
    "    \"executor-memory\": \"3G\",\n",
    "    \"executor-memoryOverhead\": \"10G\",\n",
    "    \"executor-cores\": \"1\"\n",
    "}\n",
    "\n",
    "title=\"UNet_S1S2_{}_{}_{}\".format(aoi_name, startdate, enddate)\n",
    "job = segmentationband.create_job(out_format=\"NetCDF\", title=title, job_options=job_options)\n",
    "job.start_job()\n",
    "\n",
    "# outputfile = \"{}.nc\".format(title)\n",
    "# %time result = segmentationband.execute_batch(outputfile=outputfile, job_options=job_options) # to run instantly within notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up job status\n",
    "connection.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download result\n",
    "path_result = download_job_result(connection.job(\"j-b8e6abf0ff0745dca767925436d14420\"), os.getcwd(), fformat=\"nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate result\n",
    "ds = xr.open_dataset(path_result)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = int(np.ceil(np.sqrt(len(ds.t.values))))\n",
    "fig, ax = plt.subplots(nc, nc, figsize=(3*nc, 3*nc))\n",
    "for t, subax in zip(ds.t.values, ax.ravel()):\n",
    "    subax.imshow(ds[\"prediction\"].sel(t=t), vmin=0, vmax=1)\n",
    "    subax.set_title(pd.to_datetime(t).strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local UDF debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For local debugging, these are the steps to follow:\n",
    "- Download the dataset\n",
    "- Save a subset that is the same size as the neighborhood\n",
    "- Run execute_local_udf (make sure path to UDF is defined, and is accessible)\n",
    "- Inspect the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_testinput = 'unet-s1-s2_test-input.nc'\n",
    "path_testsubset = \"unet-s1-s2_test-subset.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test dataset\n",
    "input_data.download(path_testinput, format='NetCDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect test data\n",
    "ds_test = xr.open_dataset(path_testinput)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(make_plotting_array(ds_test[[\"B04\", \"B03\", \"B02\"]].sel(t=ds_subset.t.values[0]).to_array().transpose(\"y\", \"x\", \"variable\")))\n",
    "plt.show()\n",
    "\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test subset for local debugging\n",
    "ds_subset = ds_test.sel(x=ds_test.x.values[400:520], y=ds_test.y.values[400:520]) # select ranges based on visual inspection\n",
    "if os.path.exists(path_testsubset):\n",
    "    os.remove(path_testsubset)\n",
    "ds_subset.to_netcdf(path_testsubset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect subset \n",
    "ds_subset = xr.open_dataset(path_testsubset)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(make_plotting_array(ds_subset[[\"B04\", \"B03\", \"B02\"]].sel(t=ds_subset.t.values[0]).to_array().transpose(\"y\", \"x\", \"variable\")))\n",
    "plt.show()\n",
    "\n",
    "ds_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model locally\n",
    "from openeo.udf.run_code import execute_local_udf\n",
    "\n",
    "udf = Path(\"unet_s1s2_timerange.py\").read_text()\n",
    "ds_res = execute_local_udf(udf, path_testsubset, fmt=\"netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate results\n",
    "ds_test = xr.open_dataset(path_testsubset)\n",
    "\n",
    "res_array = ds_res.get_datacube_list()[0].get_array()\n",
    "print(res_array.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_indices = np.where(ds_test[\"B02\"].notnull().sum(dim=[\"x\", \"y\"]) > 0)[0]\n",
    "s1_date_indices = np.where(ds_test[\"VV\"].notnull().sum(dim=[\"x\", \"y\"]) > 0)[0]\n",
    "\n",
    "patch_size = ds_test.sizes[\"x\"]\n",
    "\n",
    "## calculate valid px count for S-1\n",
    "s1_validpx_count = ds_test[\"VV\"].notnull().sum(dim=[\"x\", \"y\"]).values[s1_date_indices] # number of valid pixels per timestamp\n",
    "\n",
    "fig, ax = plt.subplots(3, len(s2_date_indices), figsize=(10, 4))\n",
    "for i_s2, i_t_s2 in enumerate(s2_date_indices):\n",
    "    datetag = pd.to_datetime(str(ds_test.t.values[i_t_s2])).strftime(\"%Y-%m-%d\")\n",
    "    ## find matching S-1 scene\n",
    "    time_differences = np.array([(el - ds_test.t.values[i_t_s2]) / np.timedelta64(1, \"D\") for el in ds_test.t.values[s1_date_indices]]) # unit: days\n",
    "    i_s1 = np.random.choice(np.where(abs(time_differences) == np.min(abs(time_differences[s1_validpx_count >= 0.9 * patch_size**2])))[0])\n",
    "    i_t_s1 = s1_date_indices[i_s1]\n",
    "\n",
    "    ax[0, i_s2].imshow(np.moveaxis(np.array([scale_sentinel(ds_test[b].isel(t=i_t_s2).values.copy(), b, 0, 1) for b in [\"B08\", \"B03\", \"B02\"]]), 0, -1), vmin=-1, vmax=1, cmap=\"gray\")\n",
    "    ax[0, i_s2].set_title(\"{}: B12\".format(datetag), fontsize=6)\n",
    "    ax[1, i_s2].imshow(scale_sentinel(ds_test[\"VV\"].isel(t=i_t_s1).values.copy(), \"VV\"), vmin=-1, vmax=1, cmap=\"gray\")\n",
    "    ax[1, i_s2].set_title(\"{}: VV\".format(datetag), fontsize=6)\n",
    "    ax[2, i_s2].imshow(res_array[i_s2, 0, :, :], vmin=0, vmax=1)\n",
    "    ax[2, i_s2].set_title(\"{}: pred\".format(datetag), fontsize=6)\n",
    "for subax in ax.ravel():\n",
    "    subax.set_xticks([])\n",
    "    subax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
