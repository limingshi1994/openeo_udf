{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet-based water detection on scene level using openEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to demonstrate how to do model inference using openEO. This can be done using a user-defined function (https://open-eo.github.io/openeo-python-client/udf.html). \n",
    "\n",
    "Below two U-Nets for water detection can be applied, 1) using Sentinel-2 bands B2, B3, B4 and B8, and 2) using Sentinel-2 bands B2, B3, B4, B8, B11 and B12 as well as Sentinel-1 bands VV and VH.\n",
    "\n",
    "The final section illustrates how to locally debug when developping your UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import shape, box\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import openeo\n",
    "import contextily as cx\n",
    "## For local test\n",
    "from pathlib import Path\n",
    "from openeo.udf import execute_local_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plotting_array(dataarray, vmin=0, vmax=0.25, scale=1e4):\n",
    "    \"\"\" scale xr array to 0-1 using the defined lower and upper limits and scale, for plotting with matplotlib \"\"\"\n",
    "    arr = dataarray.copy()\n",
    "    arr = arr.where(arr <= scale)\n",
    "    arr /= scale\n",
    "    arr = arr.where(arr < vmax, vmax)\n",
    "    arr = arr.where(arr > vmin, vmin)\n",
    "    return (arr - vmin) / (vmax - vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_job_result(job, dir_output, fformat=\"nc\"):\n",
    "    \"\"\" download job result to specifed output directory, file name is taken from job title \"\"\"\n",
    "    if job.status() != \"finished\":\n",
    "        print(\"Job status '{}', aborting.\".format(job.status()))\n",
    "        return None\n",
    "    # Get the results\n",
    "    results = job.get_results()\n",
    "    # Loop over the resulting assets and download        \n",
    "    for i_a, asset in enumerate(results.get_assets()):\n",
    "        asset_suffix = \"-{}\".format(i_a) if i_a > 0 else \"\"\n",
    "        asset_targetname = os.path.join(dir_output, \"{}{}.{}\".format(job.describe_job()[\"title\"], asset_suffix, fformat))\n",
    "        if os.path.exists(asset_targetname):\n",
    "            asset_targetname = asset_targetname.replace(\".{}\".format(fformat), \"-new.{}\".format(fformat))\n",
    "        print(\"{} - Downloading {}\".format(datetime.datetime.now(), asset_targetname))\n",
    "        ts = datetime.datetime.now()\n",
    "        asset.download(asset_targetname)\n",
    "        te = datetime.datetime.now()\n",
    "        print(\"\\tDownload finished after {} sec.\".format(round((te-ts).total_seconds())))\n",
    "    return asset_targetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unet_s1s2_timerange'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mf:\\work\\udf\\openeo_udf\\ours\\U-Net_openEO_EastFlanders.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munet_s1s2_timerange\u001b[39;00m \u001b[39mimport\u001b[39;00m scale_sentinel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unet_s1s2_timerange'"
     ]
    }
   ],
   "source": [
    "from unet_s1s2_timerange import scale_sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.rest.connection:Found OIDC providers: ['egi', 'egi-dev', 'terrascope', 'CDSE']\n",
      "INFO:openeo.rest.connection:No OIDC provider given. Using first provider 'egi' as advertised by backend.\n",
      "INFO:openeo.rest.connection:Using default client_id 'vito-default-client' from OIDC provider 'egi' info.\n",
      "INFO:openeo.rest.connection:Found refresh token: trying refresh token based authentication.\n",
      "INFO:openeo.rest.auth.oidc:Doing 'refresh_token' token request 'https://aai.egi.eu/auth/realms/egi/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'refresh_token'] (client_id 'vito-default-client')\n",
      "INFO:openeo.rest.connection:Obtained tokens: ['access_token', 'id_token']\n",
      "INFO:openeo.rest.auth.config:Storing refresh token for issuer 'https://aai.egi.eu/auth/realms/egi/' (client 'vito-default-client')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Connection to 'https://openeo.vito.be/openeo/1.1/' with OidcBearerAuth>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to openeo backend\n",
    "connection = openeo.connect(\"openeo.vito.be\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters: AOI bounds, year, month\n",
    "aoi_name = \"EastFlandersSmall\" #\"EastFlanders\"\n",
    "year = 2022\n",
    "month = 5\n",
    "\n",
    "aoi_bounds = [506800, 5640100, 553400, 5650900] #[466800, 5616100, 603400, 5693900]\n",
    "crs_epsg = 32631\n",
    "\n",
    "spatial_extent = dict(zip([\"west\", \"south\", \"east\", \"north\"], aoi_bounds)) # box(*aoi_bounds).buffer(-30000).bounds)\n",
    "spatial_extent[\"crs\"] = crs_epsg\n",
    "\n",
    "startdate = \"{}-{:02d}-{:02d}\".format(year, month, 1)\n",
    "enddate = \"{}-{:02d}-{:02d}\".format(year, month+1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water detection based on Sentinel-2 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run our UDF on the data cube using the apply_neighborhood() process. We can pass additional arguments for the UDF, like the model path, using the context argument. The size parameter defines the core size of the neighborhoods that are stitched back together, the overlap parameter defines the padding added at each size. So your U-Net should take patches of size+2*overlap as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path (should be stored on MEP)\n",
    "model_dir = \"/work/udf/ours/saved_models/model_20230919084756_bestvalacc.pth\"\n",
    "#path_model = \"/data/users/Public/landuytl/water-detection/PS120_2100-SY-FW0.9_MOP0.005_MOT0.80_S0_C0_2100_S2-4B_D3_F32_W-E_A0_SN_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bands in alignment with model inputs\n",
    "# bands_s2 = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "bands = [\"B04\", \"B03\", \"B02\", \"SCL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datacube\n",
    "input_data = connection.load_collection(\n",
    "    \"TERRASCOPE_S2_TOC_V2\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentationband = input_data.apply_neighborhood(\n",
    "    lambda data: data.run_udf(udf=Path('./unet_udf.py').read_text(), \n",
    "                              runtime='Python', \n",
    "                              context={\"model_path\": \"./saved_models/model_20230919084756_bestvalacc.pth\",\n",
    "    \"model_backbone\": \"Unet\",\n",
    "    \"encoder\": \"timm-regnety_320\",\n",
    "    \"pretrain\": \"imagenet\",\n",
    "    \"in_channel\": 3,\n",
    "    \"classes\": 14}),\n",
    "    size=[\n",
    "        {'dimension': 'x', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 't', 'value': 'P1D'} # this will map the UDF on every scene in the collection (https://en.wikipedia.org/wiki/ISO_8601#Durations)\n",
    "    ],\n",
    "    overlap=[\n",
    "        {'dimension': 'x', 'value': 10, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 10, 'unit': 'px'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "segmentationband = segmentationband.rename_labels(dimension=\"bands\", target=[\"prediction\"] + [\"\"] * (len(bands)-1))\n",
    "segmentationband = segmentationband.filter_bands([\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openeo.udf.run_code:Found datacube mapping UDF `apply_datacube` <function apply_datacube at 0x000001A9C47B6790>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "('t', 'bands', 'y', 'x')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('bands', 'y', 'x') must be a permuted list of ('t', 'bands', 'y', 'x'), unless `...` is included",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\work\\udf\\openeo_udf\\ours\\U-Net_openEO_EastFlanders.ipynb Cell 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m input_data\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39m./test_input.nc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNetCDF\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m local_udf \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39m./unet_udf.py\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mread_text()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m execute_local_udf(local_udf, \u001b[39m'\u001b[39;49m\u001b[39m./test_input.nc\u001b[39;49m\u001b[39m'\u001b[39;49m, usr_cont\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmodel_path\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m./saved_models/model_20230919084756_bestvalacc.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mmodel_backbone\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mUnet\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mencoder\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mtimm-regnety_320\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpretrain\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39min_channel\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m3\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/work/udf/openeo_udf/ours/U-Net_openEO_EastFlanders.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mclasses\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m14\u001b[39;49m}, fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnetcdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\openeo\\udf\\run_code.py:220\u001b[0m, in \u001b[0;36mexecute_local_udf\u001b[1;34m(udf, datacube, usr_cont, fmt)\u001b[0m\n\u001b[0;32m    214\u001b[0m udf_data \u001b[39m=\u001b[39m UdfData(datacube_list\u001b[39m=\u001b[39m[d], user_context\u001b[39m=\u001b[39musr_cont)\n\u001b[0;32m    216\u001b[0m \u001b[39m# TODO: enrich to other types like time series, vector data,... probalby by adding  named arguments\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m# signature: UdfData(proj, datacube_list, feature_collection_list, structured_data_list, ml_model_list, metadata)\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[0;32m    219\u001b[0m \u001b[39m# run the udf through the same routine as it would have been parsed in the backend\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m result \u001b[39m=\u001b[39m run_udf_code(udf, udf_data)\n\u001b[0;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\openeo\\udf\\run_code.py:175\u001b[0m, in \u001b[0;36mrun_udf_code\u001b[1;34m(code, data)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe provided UDF expects exactly one datacube, but \u001b[39m\u001b[39m{c}\u001b[39;00m\u001b[39m were provided.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    172\u001b[0m         c\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mget_datacube_list())\n\u001b[0;32m    173\u001b[0m     ))\n\u001b[0;32m    174\u001b[0m \u001b[39m# TODO: also support calls without user context?\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m result_cube \u001b[39m=\u001b[39m func(cube\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mget_datacube_list()[\u001b[39m0\u001b[39;49m], context\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49muser_context)\n\u001b[0;32m    176\u001b[0m data\u001b[39m.\u001b[39mset_datacube_list([result_cube])\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m<string>:91\u001b[0m, in \u001b[0;36mapply_datacube\u001b[1;34m(cube, context)\u001b[0m\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\xarray\\core\\dataarray.py:2992\u001b[0m, in \u001b[0;36mDataArray.transpose\u001b[1;34m(self, transpose_coords, missing_dims, *dims)\u001b[0m\n\u001b[0;32m   2959\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a new DataArray object with transposed dimensions.\u001b[39;00m\n\u001b[0;32m   2960\u001b[0m \n\u001b[0;32m   2961\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2989\u001b[0m \u001b[39mDataset.transpose\u001b[39;00m\n\u001b[0;32m   2990\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2991\u001b[0m \u001b[39mif\u001b[39;00m dims:\n\u001b[1;32m-> 2992\u001b[0m     dims \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(utils\u001b[39m.\u001b[39;49minfix_dims(dims, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdims, missing_dims))\n\u001b[0;32m   2993\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariable\u001b[39m.\u001b[39mtranspose(\u001b[39m*\u001b[39mdims)\n\u001b[0;32m   2994\u001b[0m \u001b[39mif\u001b[39;00m transpose_coords:\n",
      "File \u001b[1;32mf:\\conda\\envs\\stu\\lib\\site-packages\\xarray\\core\\utils.py:816\u001b[0m, in \u001b[0;36minfix_dims\u001b[1;34m(dims_supplied, dims_all, missing_dims)\u001b[0m\n\u001b[0;32m    814\u001b[0m existing_dims \u001b[39m=\u001b[39m drop_missing_dims(dims_supplied, dims_all, missing_dims)\n\u001b[0;32m    815\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(existing_dims) \u001b[39m^\u001b[39m \u001b[39mset\u001b[39m(dims_all):\n\u001b[1;32m--> 816\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    817\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdims_supplied\u001b[39m}\u001b[39;00m\u001b[39m must be a permuted list of \u001b[39m\u001b[39m{\u001b[39;00mdims_all\u001b[39m}\u001b[39;00m\u001b[39m, unless `...` is included\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    818\u001b[0m     )\n\u001b[0;32m    819\u001b[0m \u001b[39myield from\u001b[39;00m existing_dims\n",
      "\u001b[1;31mValueError\u001b[0m: ('bands', 'y', 'x') must be a permuted list of ('t', 'bands', 'y', 'x'), unless `...` is included"
     ]
    }
   ],
   "source": [
    "## Local test\n",
    "input_data.download('./test_input.nc', format='NetCDF')\n",
    "local_udf = Path('./unet_udf.py').read_text()\n",
    "execute_local_udf(local_udf, './test_input.nc', usr_cont={\"model_path\": \"./saved_models/model_20230919084756_bestvalacc.pth\",\n",
    "    \"model_backbone\": \"Unet\",\n",
    "    \"encoder\": \"timm-regnety_320\",\n",
    "    \"pretrain\": \"imagenet\",\n",
    "    \"in_channel\": 3,\n",
    "    \"classes\": 14}, fmt='netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default job resources are 2 executor cores with 2G memory en 3G memory overhead, but these need to be increased for larger AOIs. See https://docs.openeo.cloud/federation/#customizing-batch-job-resources-on-terrascope for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job\n",
    "\n",
    "job_options = { # trial-error based, I'm currently using 2G/6G for the smaller AOIs and 8G/8G for the larger AOIs\n",
    "    \"executor-memory\": \"8G\",\n",
    "    \"executor-memoryOverhead\": \"8G\",\n",
    "    \"executor-cores\": \"4\"\n",
    "}\n",
    "\n",
    "job = segmentationband.create_job(out_format=\"NetCDF\", title=\"BVM_{}_{}_{}\".format(aoi_name, startdate, enddate), job_options=job_options)\n",
    "job.start_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up job status\n",
    "connection.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"j-2311143fadc44b3b8c830e2001ebeaab\"\n",
    "j = connection.job(job_id)\n",
    "j.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download result based on job id\n",
    "job_id = \"j-47673edec3104751a2764aa76d257f42\"\n",
    "path_result = download_job_result(connection.job(job_id), os.getcwd(), fformat=\"nc\")\n",
    "print(path_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate result\n",
    "ds = xr.open_dataset(path_result)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of results\n",
    "nc = 4\n",
    "fig, ax = plt.subplots(nc, nc, figsize=(3*nc, 3*nc))\n",
    "for subax in ax.ravel():\n",
    "    t = np.random.choice(ds.t.values)\n",
    "    subax.imshow(ds[\"prediction\"].sel(t=t).values, vmin=0, vmax=1)\n",
    "    subax.set_title(pd.to_datetime(t).strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Water detection based on Sentinel-2 & Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a U-Net requiring both Sentinel-2 and Sentinel-1 input, we need to first temporally align both. This is done within the UDF: for each S-2 scene, the closest S-1 scene that has less nan values than all candidates is selected.\n",
    "\n",
    "We will first extract the dates on which S-1 and S-2 scenes are available, so we can pass this info to the UDF. As we need access to more than just 1 date value to be able to select the closest S-1 scene, we will pass the full datacube to the UDF (size for t dimension undefined), and make the UDF return the full S-2 time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny AOI for testing (temporary)\n",
    "aoi_bounds = [513270, 5644200, 517690, 5647900] #[466800, 5616100, 603400, 5693900]\n",
    "crs_epsg = 32631\n",
    "\n",
    "spatial_extent = dict(zip([\"west\", \"south\", \"east\", \"north\"], aoi_bounds)) # box(*aoi_bounds).buffer(-30000).bounds)\n",
    "spatial_extent[\"crs\"] = crs_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "path_model = \"/data/users/Public/landuytl/water-detection/PS120_2100-SY-FW0.9_MOP0.005_MOT0.80_S0_C1_2100_S2-6B-S1_D3_F32_W-E_A0_fromscratch_best.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bands in alignment with model inputs\n",
    "bands_s2 = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\", \"SCL\"]\n",
    "bands_s1 = [\"VV\", \"VH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datacube\n",
    "\n",
    "# Get all S2 data\n",
    "input_data_s2 = connection.load_collection(\n",
    "    \"TERRASCOPE_S2_TOC_V2\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands_s2,\n",
    ")\n",
    "\n",
    "# Get all S1 data\n",
    "input_data_s1 = connection.load_collection(\n",
    "    \"SENTINEL1_GRD_SIGMA0\",\n",
    "    temporal_extent=[startdate, enddate],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=bands_s1,\n",
    ")\n",
    "\n",
    "input_data = input_data_s2.merge_cubes(input_data_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S-1 & S-2 dates to pass as input to UDF\n",
    "# input_data_s2.dimension_labels(\"t\").download(\"dates_s2.json\")\n",
    "# input_data_s1.dimension_labels(\"t\").download(\"dates_s1.json\")\n",
    "s1_dates = input_data_s1.dimension_labels(\"t\").execute()\n",
    "s2_dates = input_data_s2.dimension_labels(\"t\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model on openeo server\n",
    "\n",
    "segmentationband = input_data.apply_neighborhood(\n",
    "    lambda data: data.run_udf(udf=Path('unet_s1s2_timerange.py').read_text(), \n",
    "                              runtime='Python', \n",
    "                              context={\"path_model\": path_model,\n",
    "                                      \"s2_dates\": s2_dates,\n",
    "                                      \"s1_dates\": s1_dates}),\n",
    "    size=[\n",
    "        {'dimension': 'x', 'value': 100, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 100, 'unit': 'px'}\n",
    "    ],\n",
    "    overlap=[\n",
    "        {'dimension': 'x', 'value': 10, 'unit': 'px'},\n",
    "        {'dimension': 'y', 'value': 10, 'unit': 'px'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "segmentationband = segmentationband.rename_labels(dimension=\"bands\", target=[\"prediction\"] + [\"\"] * (len(bands_s2)+len(bands_s1)-1))\n",
    "segmentationband = segmentationband.filter_bands([\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job\n",
    "\n",
    "job_options = {\n",
    "    \"executor-memory\": \"3G\",\n",
    "    \"executor-memoryOverhead\": \"10G\",\n",
    "    \"executor-cores\": \"1\"\n",
    "}\n",
    "\n",
    "title=\"UNet_S1S2_{}_{}_{}\".format(aoi_name, startdate, enddate)\n",
    "job = segmentationband.create_job(out_format=\"NetCDF\", title=title, job_options=job_options)\n",
    "job.start_job()\n",
    "\n",
    "# outputfile = \"{}.nc\".format(title)\n",
    "# %time result = segmentationband.execute_batch(outputfile=outputfile, job_options=job_options) # to run instantly within notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow up job status\n",
    "connection.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download result\n",
    "path_result = download_job_result(connection.job(\"j-b8e6abf0ff0745dca767925436d14420\"), os.getcwd(), fformat=\"nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate result\n",
    "ds = xr.open_dataset(path_result)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = int(np.ceil(np.sqrt(len(ds.t.values))))\n",
    "fig, ax = plt.subplots(nc, nc, figsize=(3*nc, 3*nc))\n",
    "for t, subax in zip(ds.t.values, ax.ravel()):\n",
    "    subax.imshow(ds[\"prediction\"].sel(t=t), vmin=0, vmax=1)\n",
    "    subax.set_title(pd.to_datetime(t).strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local UDF debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For local debugging, these are the steps to follow:\n",
    "- Download the dataset\n",
    "- Save a subset that is the same size as the neighborhood\n",
    "- Run execute_local_udf (make sure path to UDF is defined, and is accessible)\n",
    "- Inspect the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_testinput = 'unet-s1-s2_test-input.nc'\n",
    "path_testsubset = \"unet-s1-s2_test-subset.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test dataset\n",
    "input_data.download(path_testinput, format='NetCDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect test data\n",
    "ds_test = xr.open_dataset(path_testinput)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(make_plotting_array(ds_test[[\"B04\", \"B03\", \"B02\"]].sel(t=ds_subset.t.values[0]).to_array().transpose(\"y\", \"x\", \"variable\")))\n",
    "plt.show()\n",
    "\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test subset for local debugging\n",
    "ds_subset = ds_test.sel(x=ds_test.x.values[400:520], y=ds_test.y.values[400:520]) # select ranges based on visual inspection\n",
    "if os.path.exists(path_testsubset):\n",
    "    os.remove(path_testsubset)\n",
    "ds_subset.to_netcdf(path_testsubset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect subset \n",
    "ds_subset = xr.open_dataset(path_testsubset)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(make_plotting_array(ds_subset[[\"B04\", \"B03\", \"B02\"]].sel(t=ds_subset.t.values[0]).to_array().transpose(\"y\", \"x\", \"variable\")))\n",
    "plt.show()\n",
    "\n",
    "ds_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model locally\n",
    "from openeo.udf.run_code import execute_local_udf\n",
    "\n",
    "udf = Path(\"unet_s1s2_timerange.py\").read_text()\n",
    "ds_res = execute_local_udf(udf, path_testsubset, fmt=\"netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate results\n",
    "ds_test = xr.open_dataset(path_testsubset)\n",
    "\n",
    "res_array = ds_res.get_datacube_list()[0].get_array()\n",
    "print(res_array.sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_indices = np.where(ds_test[\"B02\"].notnull().sum(dim=[\"x\", \"y\"]) > 0)[0]\n",
    "s1_date_indices = np.where(ds_test[\"VV\"].notnull().sum(dim=[\"x\", \"y\"]) > 0)[0]\n",
    "\n",
    "patch_size = ds_test.sizes[\"x\"]\n",
    "\n",
    "## calculate valid px count for S-1\n",
    "s1_validpx_count = ds_test[\"VV\"].notnull().sum(dim=[\"x\", \"y\"]).values[s1_date_indices] # number of valid pixels per timestamp\n",
    "\n",
    "fig, ax = plt.subplots(3, len(s2_date_indices), figsize=(10, 4))\n",
    "for i_s2, i_t_s2 in enumerate(s2_date_indices):\n",
    "    datetag = pd.to_datetime(str(ds_test.t.values[i_t_s2])).strftime(\"%Y-%m-%d\")\n",
    "    ## find matching S-1 scene\n",
    "    time_differences = np.array([(el - ds_test.t.values[i_t_s2]) / np.timedelta64(1, \"D\") for el in ds_test.t.values[s1_date_indices]]) # unit: days\n",
    "    i_s1 = np.random.choice(np.where(abs(time_differences) == np.min(abs(time_differences[s1_validpx_count >= 0.9 * patch_size**2])))[0])\n",
    "    i_t_s1 = s1_date_indices[i_s1]\n",
    "\n",
    "    ax[0, i_s2].imshow(np.moveaxis(np.array([scale_sentinel(ds_test[b].isel(t=i_t_s2).values.copy(), b, 0, 1) for b in [\"B08\", \"B03\", \"B02\"]]), 0, -1), vmin=-1, vmax=1, cmap=\"gray\")\n",
    "    ax[0, i_s2].set_title(\"{}: B12\".format(datetag), fontsize=6)\n",
    "    ax[1, i_s2].imshow(scale_sentinel(ds_test[\"VV\"].isel(t=i_t_s1).values.copy(), \"VV\"), vmin=-1, vmax=1, cmap=\"gray\")\n",
    "    ax[1, i_s2].set_title(\"{}: VV\".format(datetag), fontsize=6)\n",
    "    ax[2, i_s2].imshow(res_array[i_s2, 0, :, :], vmin=0, vmax=1)\n",
    "    ax[2, i_s2].set_title(\"{}: pred\".format(datetag), fontsize=6)\n",
    "for subax in ax.ravel():\n",
    "    subax.set_xticks([])\n",
    "    subax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
